---
title: 10x Your RAG Evaluation
subtitle: by Avoiding these Pitfalls
author: Skylar Payne
format: 
  revealjs:
    theme: [beige, styles.scss]
    smaller: true
    highlight-style: arrow
    table-format:
        hover: true
execute:
    enabled: false
---

## The Problem

RAG systems fail silently, and teams struggle to debug them.

:::{.columns}

:::{.column width="50%"}
![](assets/before_after.png)
:::

:::{.column width="50%"}
<br>

- "answer looks wrong" provides no actionable debugging path
- Silent failures accumulate as technical debt  
- Teams waste time guessing what's broken
:::

:::

**Goal**: Build systematic evaluation into your RAG pipeline

---

## About Me

::: {.columns}

::: {.column width="30%"}
![Skylar Payne](https://skylarbpayne.com/assets/images/headshot.jpg)
:::

::: {.column width="70%"}
:::{.special}
Empowering **you** to build AI products users **love**.  
And permanently ditch those 3 AM debugging sessions.
:::

- Building AI products for **over a decade** at Google, LinkedIn, and in AI based diagnostics (healthcare)
- Trained **over 100 engineers** to build AI products
- Hands on executive experience building the teams that build AI products

**Fun fact**: my favorite movie is Mean Girls (I have a party for it every October 3rd).

<div class="tenor-gif-embed" data-postid="4135521" data-share-method="host" data-aspect-ratio="1.77778" data-width="30%"><a href="https://tenor.com/view/so-fetch-mean-girls-fetch-trending-look-good-gif-4135521">So Fetch GIF</a>from <a href="https://tenor.com/search/so+fetch-gifs">So Fetch GIFs</a></div> <script type="text/javascript" async src="https://tenor.com/embed.js"></script>
:::

:::

---

## The Only Thing to Remember

:::{.fragment}
**Look. At. Your. Data.**
:::

:::{.fragment}
Seriously. That's it.
:::

:::{.fragment}
I really mean it. Look at it.
:::

---

## Guiding principle

:::{.fragment .special}
evaluate everything, independently if possible
:::

:::{.fragment}
Most people do not "eval" anything.
:::

:::{.fragment}
Fewer people evaluate generation.
:::

:::{.fragment}
Even fewer people evaluate retrieval.
:::

:::{.fragment}
Even fewer people evaluate indexing.
:::

:::{.fragment}
To fix anything, you must understand *where* it is broken.  
Evaluation at multiple critical stages is the only way to do this consistently.
:::

---

## Common Pitfalls

:::{.fragment}
Every single pitfall here is something I have seen in my work with clients. And addressing it has always provided signficant improvements.
:::

---

## Pitfall #1: Corpus Coverage

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Do we have all the documents we need?
:::

:::{.column width="60%"}
```
Use case: "How do I integrate with Salesforce?"
Search results: 0 relevant chunks

Reality: Integration exists but no docs were written

The cost: Lost customers who assume you don't support their stack
```

**Evaluation Test**:  
Measure % of queries that return relevant chunks across your entire corpus

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/corpus_coverage.png)
:::
:::

---

## Pitfall #2: Information Extraction

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Do we understand the content well enough?
:::

:::{.column width="60%"}
```
Bad format:
"See attached PDF for API documentation (link broken)"

Good format:
"API Authentication: Use Bearer tokens in the Authorization header.
Example: Authorization: Bearer your_token_here"
```

**Evaluation Test**:  
Verify tables, code blocks, and structured data are correctly parsed

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/information_extraction.png)
:::
:::

---

## Pitfall #3: Chunk Quality

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Meaningful chunking that balances relevancy?
:::

:::{.column width="60%"}
```
Bad chunking:
Chunk 1: "To set up authentication, first install the SDK"
Chunk 2: "Then configure your API key in the dashboard"
Chunk 3: "Finally, add the auth middleware to your app"

Good chunking:
Chunk 1: "Authentication Setup:
1. Install SDK: npm install frigade-sdk
2. Configure API key in dashboard  
3. Add auth middleware to your app"
```

**Evaluation Test**:  
Look at samples of large chunks, small chunks, frequently retrieved, and rarely retrieved chunks

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/chunk_quality.png)
:::
:::

---

## Pitfall #4: Query Rejection

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Was the query well-formed?
:::

:::{.column width="60%"}
```
Unclear query: "thing broken"
Clear query: "Why is my API authentication failing with 401 error?"

Unclear query: "pricing info"  
Clear query: "What are the pricing tiers for enterprise customers?"
```

**Evaluation Test**:  
Calculate rejection rate and elicitation rate for unclear queries

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/vague_query.png)
:::
:::

---

## Pitfall #5: Retrieval Sufficiency

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Did we get enough relevant docs?
:::

:::{.column width="60%"}
```
Query: "How do I implement user segmentation?"
Retrieved chunks:
- "User segmentation allows personalized experiences" ✓ relevant
- "Create segments based on user behavior" ✓ relevant  
- "Segments can be used for targeting" ✓ relevant

Missing: The actual implementation steps!
```

**Evaluation Test**:  
Evaluate % of queries that retrieve sufficient information to answer the question completely

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/sufficiency.png)
:::
:::

---

## Pitfall #6: Hallucination

:::{.columns}

:::{.special style="margin-bottom: 2em;"}
Did the generation hallucinate?
:::

:::{.column width="60%"}
```
Retrieved Context: "Our API rate limit is 1,000 requests per minute"
Generated Answer: "The API supports up to 500 requests per minute 
with burst capacity up to 2,000 for enterprise users"

Problem: Where did "500" and "enterprise burst capacity" come from?
```

**Evaluation Test**:  
Force in-text citations in responses and validate each citation exists and is relevant

:::

:::{.column width="10%"}
:::

:::{.column width="30%"}
![](assets/hallucination.png)
:::
:::

---

## A Generic Failure Funnel for RAG Systems

This is a generic failure funnel I like to use when evaluating RAG systems.  
Domain specific is always better, but I have found this to be a decent starting point.

```{mermaid}
flowchart LR
  A[Query Understood]
  B[Relevant Documents Exist]
  C[Relevant Documents Well-Structured]
  D[Relevant Documents Retrieved]
  E[Sufficient Retrieval]
  F[No Hallucination]
  G[Correct Answer]
  H[Right Format]

  A --> B
  B --> C
  C --> D
  D --> E
  E --> F
  F --> G
  G --> H
```

- queries that are vague or ambiguous need to elicit more information
- queries without any relevant retrieval likely mean information extraction is broken
- queries that do not have sufficient retrieval likely mean retrieval needs work
- queries that have hallucination likely mean context/prompting needs work
- queries that have incorrect answers may mean stronger models, reasoning, etc needed
- queries that have the wrong tone/format may require more examples, better prompting, etc

---

## Questions?

**Thank you!**

:::{.columns}

:::{.column width="50%"}
:::

:::{.column width="50%"}
:::{.special}
**Sign up for my newsletter!**
:::

Empowering *you* to build AI products users **love**.

![](assets/newsletter-qr.png)
:::

:::
